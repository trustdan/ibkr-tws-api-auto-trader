# 05-metrics-and-logging.md

## 1. Overview

This document outlines how to add observability to the Go Scanner service through Prometheus metrics and structured logging. Proper instrumentation will allow us to:

* **Monitor scan performance** in real-time
* **Track signal patterns** being detected across the universe
* **Troubleshoot errors** and bottlenecks in the scanner pipeline
* **Alert** on anomalies or degraded performance

Key components:

* **Prometheus Metrics**: Histograms for latency, counters for operation counts, gauges for in-flight operations
* **Structured Logging**: JSON-formatted logs with consistent context fields and log levels
* **HTTP Endpoint**: Exposing metrics for scraping by Prometheus
* **Context Propagation**: Carrying trace IDs through the scanning pipeline

## 2. Metrics Implementation

### 2.1. Dependencies

First, add the required dependencies to your Go project:

```bash
go get github.com/prometheus/client_golang/prometheus
go get github.com/prometheus/client_golang/prometheus/promauto
go get github.com/prometheus/client_golang/prometheus/promhttp
go get github.com/sirupsen/logrus  # We'll use logrus for structured logging
```

Update your `go.mod` file by running:

```bash
go mod tidy
```

### 2.2. Define Metrics Registry

Create `pkg/metrics/metrics.go` to centralize all metrics definitions:

```go
package metrics

import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    // ScanRequests tracks the total number of scan requests
    ScanRequests = promauto.NewCounter(prometheus.CounterOpts{
        Name: "scanner_requests_total",
        Help: "Total number of scan requests received",
    })

    // ScanDuration tracks the duration of symbol scans
    ScanDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "scanner_scan_duration_seconds",
            Help:    "Duration of symbol scan operations in seconds",
            Buckets: prometheus.DefBuckets, // Default buckets: .005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10
        },
        []string{"symbol"},
    )

    // ScanResults counts signals generated by type
    ScanResults = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "scanner_signals_total",
            Help: "Total number of signals generated by type",
        },
        []string{"signal_type"},
    )

    // DataFetchErrors counts failed requests to the market data service
    DataFetchErrors = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "scanner_data_fetch_errors_total",
            Help: "Total number of errors fetching market data",
        },
        []string{"error_type"},
    )

    // ActiveScans tracks the number of scans currently in progress
    ActiveScans = promauto.NewGauge(prometheus.GaugeOpts{
        Name: "scanner_active_scans",
        Help: "Number of scan operations currently in progress",
    })

    // WorkerQueueSize exposes the current size of the worker queue
    WorkerQueueSize = promauto.NewGauge(prometheus.GaugeOpts{
        Name: "scanner_worker_queue_size",
        Help: "Current size of the worker queue",
    })
)
```

### 2.3. Instrument Processor Operations

Update the `pkg/scan/processor.go` file to include metrics:

```go
import (
    "time"
    "context"
    
    "github.com/your-org/trader-scanner/pkg/metrics"
    "github.com/sirupsen/logrus"
)

// ScanSymbol scans a single symbol for trading patterns
func (p *Processor) ScanSymbol(ctx context.Context, symbol string) (*ScanResult, error) {
    // Track active scans
    metrics.ActiveScans.Inc()
    defer metrics.ActiveScans.Dec()
    
    // Start timer
    startTime := time.Now()
    
    // Create a logger with symbol context
    log := logrus.WithField("symbol", symbol)
    log.Info("Starting symbol scan")
    
    // Default result in case of error
    result := &ScanResult{
        Symbol: symbol,
        Signal: pb.SignalType_NONE,
    }
    
    // Get historical bars
    log.Debug("Requesting historical bars")
    barsResp, err := p.client.GetHistoricalBars(ctx, &pb.BarsRequest{
        Symbol: symbol,
        Days:   p.config.SMA50Period + p.config.CandleCount, // 52 days typically
    })
    
    if err != nil {
        log.WithError(err).Error("Failed to get historical bars")
        metrics.DataFetchErrors.WithLabelValues("bars_request").Inc()
        return result, err
    }
    
    // Only proceed with IV check if we have a potential pattern
    if patternDetected := p.evaluatePattern(barsResp.Bars); patternDetected {
        // Get IV percentile
        ivResp, err := p.client.GetIVPercentile(ctx, &pb.IVRequest{Symbol: symbol})
        if err != nil {
            log.WithError(err).Error("Failed to get IV percentile")
            metrics.DataFetchErrors.WithLabelValues("iv_request").Inc()
            return result, err
        }
        
        // Determine signal type based on pattern and IV
        signal := p.determineSignalType(barsResp.Bars, ivResp.Percentile)
        result.Signal = signal
        
        // Record the signal type
        metrics.ScanResults.WithLabelValues(signal.String()).Inc()
        
        log.WithField("signal", signal.String()).Info("Pattern detected")
    } else {
        log.Debug("No pattern detected")
        metrics.ScanResults.WithLabelValues("NONE").Inc()
    }
    
    // Record request and duration
    metrics.ScanRequests.Inc()
    duration := time.Since(startTime).Seconds()
    metrics.ScanDuration.WithLabelValues(symbol).Observe(duration)
    
    log.WithFields(logrus.Fields{
        "duration_ms": duration * 1000,
        "signal": result.Signal.String(),
    }).Info("Scan completed")
    
    return result, nil
}

// ScanAll scans all symbols in the configured universe
func (p *Processor) ScanAll(ctx context.Context) ([]*ScanResult, error) {
    startTime := time.Now()
    log := logrus.WithField("universe_size", len(p.config.Universe))
    log.Info("Starting universe scan")
    
    // Create a worker pool
    results := make([]*ScanResult, 0, len(p.config.Universe))
    resultChan := make(chan *ScanResult, len(p.config.Universe))
    errorChan := make(chan error, len(p.config.Universe))
    
    // Track queue size
    metrics.WorkerQueueSize.Set(float64(len(p.config.Universe)))
    defer metrics.WorkerQueueSize.Set(0)
    
    // Create worker pool with semaphore for concurrency control
    sem := make(chan struct{}, p.config.WorkerCount)
    for _, symbol := range p.config.Universe {
        // Acquire semaphore
        sem <- struct{}{}
        
        // Launch worker goroutine
        go func(sym string) {
            defer func() { <-sem } // Release semaphore
            
            // Create context with timeout
            scanCtx, cancel := context.WithTimeout(ctx, p.config.ScanTimeout)
            defer cancel()
            
            // Scan the symbol
            result, err := p.ScanSymbol(scanCtx, sym)
            if err != nil {
                errorChan <- err
                return
            }
            resultChan <- result
        }(symbol)
    }
    
    // Collect results
    for i := 0; i < len(p.config.Universe); i++ {
        select {
        case result := <-resultChan:
            results = append(results, result)
        case err := <-errorChan:
            log.WithError(err).Error("Error scanning symbol")
        case <-ctx.Done():
            log.Warn("Universe scan canceled")
            return results, ctx.Err()
        }
    }
    
    // Log completion
    duration := time.Since(startTime).Seconds()
    log.WithFields(logrus.Fields{
        "duration_ms": duration * 1000,
        "results_count": len(results),
        "errors_count": len(p.config.Universe) - len(results),
    }).Info("Universe scan completed")
    
    return results, nil
}
```

## 3. Structured Logging Setup

### 3.1. Configure Logrus

Create `pkg/logger/logger.go`:

```go
package logger

import (
    "os"
    "github.com/sirupsen/logrus"
)

// Init initializes the logger with appropriate configuration
func Init() {
    // Use JSON formatter for structured logging
    logrus.SetFormatter(&logrus.JSONFormatter{
        FieldMap: logrus.FieldMap{
            logrus.FieldKeyTime:  "timestamp",
            logrus.FieldKeyLevel: "level",
            logrus.FieldKeyMsg:   "message",
        },
    })
    
    // Set output to stdout
    logrus.SetOutput(os.Stdout)
    
    // Set log level based on environment
    level := os.Getenv("LOG_LEVEL")
    switch level {
    case "debug":
        logrus.SetLevel(logrus.DebugLevel)
    case "info":
        logrus.SetLevel(logrus.InfoLevel)
    case "warn":
        logrus.SetLevel(logrus.WarnLevel)
    case "error":
        logrus.SetLevel(logrus.ErrorLevel)
    default:
        logrus.SetLevel(logrus.InfoLevel)
    }
}

// GetLogger returns a logrus logger with standard fields
func GetLogger(component string) *logrus.Entry {
    return logrus.WithFields(logrus.Fields{
        "component": component,
        "service":   "go-scanner",
    })
}
```

### 3.2. Common Logging Patterns

Document common logging patterns for scanner operations:

```go
// Example logging patterns for scanner operations

// 1. Beginning of operation with context
log := logger.GetLogger("processor")
log.WithFields(logrus.Fields{
    "symbol": symbol,
    "config": fmt.Sprintf("%+v", p.config),
}).Info("Starting scan operation")

// 2. Debug level for detailed execution steps
log.WithField("bars_count", len(bars)).Debug("Processing historical bars")

// 3. Warning for unusual but non-fatal conditions
log.WithFields(logrus.Fields{
    "symbol": symbol,
    "iv_percentile": ivPercentile,
}).Warn("Unusually high IV percentile detected")

// 4. Error with structured context
log.WithFields(logrus.Fields{
    "symbol": symbol,
    "error": err.Error(),
    "request_id": requestID,
}).Error("Failed to fetch historical data")

// 5. Operation completion with metrics
log.WithFields(logrus.Fields{
    "duration_ms": duration * 1000,
    "signal_type": result.Signal.String(),
    "symbol": symbol,
}).Info("Scan operation completed")
```

## 4. HTTP Metrics Endpoint

### 4.1. Create Metrics Server

In `cmd/scanner/main.go`, add the metrics HTTP server:

```go
import (
    "context"
    "net/http"
    "os"
    "os/signal"
    "syscall"
    "time"
    
    "github.com/your-org/trader-scanner/pkg/logger"
    "github.com/prometheus/client_golang/prometheus/promhttp"
    "github.com/sirupsen/logrus"
)

func main() {
    // Initialize logger
    logger.Init()
    log := logger.GetLogger("main")
    
    // Parse configuration
    config := parseConfig()
    
    // Create processor and services
    // ...
    
    // Start gRPC server
    // ...
    
    // Start metrics HTTP server
    metricsServer := &http.Server{
        Addr:    ":2112",
        Handler: nil, // DefaultServeMux
    }
    
    // Register metrics endpoint
    http.Handle("/metrics", promhttp.Handler())
    
    // Add a health check endpoint
    http.HandleFunc("/health", func(w http.ResponseWriter, r *http.Request) {
        w.WriteHeader(http.StatusOK)
        w.Write([]byte("OK"))
    })
    
    // Start metrics server in a goroutine
    go func() {
        log.WithField("addr", metricsServer.Addr).Info("Starting metrics server")
        if err := metricsServer.ListenAndServe(); err != nil && err != http.ErrServerClosed {
            log.WithError(err).Fatal("Metrics server failed")
        }
    }()
    
    // Set up graceful shutdown
    shutdown := make(chan os.Signal, 1)
    signal.Notify(shutdown, os.Interrupt, syscall.SIGTERM)
    
    <-shutdown
    log.Info("Shutdown signal received")
    
    // Create shutdown context with timeout
    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
    defer cancel()
    
    // Shutdown metrics server
    if err := metricsServer.Shutdown(ctx); err != nil {
        log.WithError(err).Error("Metrics server shutdown failed")
    }
    
    // Shutdown gRPC server
    // ...
    
    log.Info("Server shutdown completed")
}
```

### 4.2. Prometheus Scrape Configuration

Document how to configure Prometheus to scrape your metrics:

```yaml
# Example prometheus.yml scrape config
scrape_configs:
  - job_name: 'go-scanner'
    scrape_interval: 15s
    static_configs:
      - targets: ['scanner-service:2112']
```

## 5. Testing Metrics and Logging

### 5.1. Unit Testing Metrics

```go
func TestMetricsRecording(t *testing.T) {
    // Reset the registry before testing
    prometheus.DefaultRegisterer = prometheus.NewRegistry()
    
    // Re-register our metrics
    metrics.ScanRequests = promauto.NewCounter(prometheus.CounterOpts{
        Name: "scanner_requests_total",
        Help: "Total number of scan requests received",
    })
    
    // Create a test processor
    proc := NewProcessor(testConfig())
    
    // Create a mock client that always returns bullish bars
    mockClient := &MockMarketDataClient{
        BarsResponse: &pb.BarsResponse{Bars: createBullishBars()},
        IVResponse: &pb.IVResponse{Percentile: 0.3},
    }
    
    proc.client = mockClient
    
    // Get the initial value
    initialValue := getCounterValue(metrics.ScanRequests)
    
    // Scan a symbol
    proc.ScanSymbol(context.Background(), "TEST")
    
    // Check that the counter increased
    newValue := getCounterValue(metrics.ScanRequests)
    if newValue <= initialValue {
        t.Errorf("Counter did not increase: initial=%f, new=%f", initialValue, newValue)
    }
}

// Helper to get counter value
func getCounterValue(counter prometheus.Counter) float64 {
    var m dto.Metric
    counter.Write(&m)
    return m.Counter.GetValue()
}
```

### 5.2. Integration Testing HTTP Endpoint

```go
func TestMetricsEndpoint(t *testing.T) {
    // Start a test server
    http.Handle("/metrics", promhttp.Handler())
    server := httptest.NewServer(http.DefaultServeMux)
    defer server.Close()
    
    // Make a scan request to generate some metrics
    processor := setupTestProcessor()
    processor.ScanSymbol(context.Background(), "TEST")
    
    // Get metrics endpoint
    resp, err := http.Get(server.URL + "/metrics")
    if err != nil {
        t.Fatalf("Failed to GET metrics: %v", err)
    }
    defer resp.Body.Close()
    
    // Check status code
    if resp.StatusCode != http.StatusOK {
        t.Errorf("Expected status 200, got %d", resp.StatusCode)
    }
    
    // Read body
    body, err := io.ReadAll(resp.Body)
    if err != nil {
        t.Fatalf("Failed to read response: %v", err)
    }
    
    // Check for expected metrics
    metrics := []string{
        "scanner_requests_total",
        "scanner_scan_duration_seconds",
        "scanner_signals_total",
    }
    
    for _, m := range metrics {
        if !strings.Contains(string(body), m) {
            t.Errorf("Expected metric %s not found", m)
        }
    }
}
```

## 6. Visualizing Metrics

### 6.1. Grafana Dashboard

Create a Grafana dashboard to visualize scanner metrics:

```json
{
  "annotations": {...},
  "editable": true,
  "panels": [
    {
      "title": "Scan Duration",
      "type": "graph",
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(scanner_scan_duration_seconds_bucket[5m])) by (le))",
          "legendFormat": "p95"
        },
        {
          "expr": "histogram_quantile(0.50, sum(rate(scanner_scan_duration_seconds_bucket[5m])) by (le))",
          "legendFormat": "p50"
        }
      ]
    },
    {
      "title": "Signal Distribution",
      "type": "pie",
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "sum(scanner_signals_total) by (signal_type)"
        }
      ]
    },
    {
      "title": "Active Scans",
      "type": "gauge",
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "scanner_active_scans"
        }
      ],
      "options": {
        "min": 0,
        "max": 20
      }
    }
  ]
}
```

## 7. Cucumber Scenarios

```gherkin
Feature: Metrics and Logging
  Scenario: Scan metrics are recorded
    Given the scanner service is running
    When a symbol scan is completed
    Then scan_requests_total counter increases
    And scan_duration_seconds histogram records the duration
    And scan_results_total counter for the signal type increases

  Scenario: Metrics endpoint exposure
    Given the scanner service is running
    When I send a GET request to "/metrics"
    Then I receive HTTP status 200
    And the response contains all defined metrics

  Scenario: Log entries for scan operations
    Given the scanner service is configured for JSON logging
    When a scanning operation is performed
    Then a structured log entry is emitted with symbol, signal_type and duration fields

  Scenario: Error handling with metrics
    Given the scanner service is running
    When a market data service error occurs
    Then scanner_data_fetch_errors_total counter increases
    And an error log entry is emitted
```

## 8. Implementation Checklist

- [ ] Add Prometheus and logrus dependencies
- [ ] Create metrics package with counters, histograms, and gauges
- [ ] Implement structured logging throughout the scanner service
- [ ] Add metrics HTTP server on port 2112
- [ ] Expose health check endpoint
- [ ] Instrument ScanSymbol and ScanAll methods
- [ ] Add tests for metrics recording
- [ ] Create Grafana dashboard for visualization
- [ ] Document configuration for production environments
